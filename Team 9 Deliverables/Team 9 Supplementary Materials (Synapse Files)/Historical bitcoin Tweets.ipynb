{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Load in data - Bitcoin Tweets 2014-2019"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "outputs": [],
      "metadata": {},
      "source": [
        "storage_account = \"ds562team9datalake\"\n",
        "container_name = \"bronze\"\n",
        "file_path = \"Crypto_tweets/bitcoinTweets_2014_2019.csv\"\n",
        "\n",
        "storage_key = \"KXg2Djg7uRevBSpPNIVnKw/N6HpqBh+kJwDX07wkywbpU2joMZdTIBOXk30EoMMxH2d8wwb+9j0g+AStO60IWw==\"\n",
        "\n",
        "spark.conf.set(f\"fs.azure.account.key.{storage_account}.blob.core.windows.net\", storage_key)\n",
        "\n",
        "url = f\"wasbs://{container_name}@{storage_account}.blob.core.windows.net/{file_path}\"\n",
        "\n",
        "df_btc_tweets = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### data source....\n",
        " https://www.kaggle.com/datasets/gauravduttakiit/bitcoin-tweets-16m-tweets-with-sentiment-tagged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import col, count, isnan, when\n",
        "\n",
        "df_btc_tweets = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(url)\n",
        "\n",
        "print(\"Schema:\")\n",
        "df_btc_tweets.printSchema()\n",
        "\n",
        "print(\"\\nNull values per column:\")\n",
        "null_counts = df_btc_tweets.select([\n",
        "    count(when(col(c).isNull() | isnan(c), c)).alias(c)\n",
        "    for c in df_btc_tweets.columns\n",
        "])\n",
        "null_counts.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Clean the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "outputs": [],
      "metadata": {},
      "source": [
        "column_names = [\"date\", \"text\", \"sentiment\"]\n",
        "\n",
        "df_btc_tweets = spark.read.option(\"header\", False).csv(url).toDF(*column_names)\n",
        "df_btc_tweets_cleaned = df_btc_tweets.filter(df_btc_tweets[\"date\"] != \"Date\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_btc_tweets_cleaned = df_btc_tweets.filter(df_btc_tweets[\"date\"] != \"Date\")\n",
        "df_btc_tweets_cleaned.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import trim\n",
        "\n",
        "df_final = df_btc_tweets_cleaned.filter(\n",
        "    (df_btc_tweets_cleaned[\"date\"].isNotNull()) & (trim(df_btc_tweets_cleaned[\"date\"]) != \"\") &\n",
        "    (df_btc_tweets_cleaned[\"text\"].isNotNull()) & (trim(df_btc_tweets_cleaned[\"text\"]) != \"\") &\n",
        "    (df_btc_tweets_cleaned[\"sentiment\"].isNotNull()) & (trim(df_btc_tweets_cleaned[\"sentiment\"]) != \"\")\n",
        ")\n",
        "print(\"Final row count with valid date, text, and sentiment:\", df_final.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import year, to_date\n",
        "\n",
        "df_final_with_year = df_final.withColumn(\"year\", year(to_date(\"date\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import year, to_date\n",
        "\n",
        "df_final_with_year = df_final.withColumn(\"year\", year(to_date(\"date\")))\n",
        "\n",
        "df_filtered_years = df_final_with_year.filter(\n",
        "    (col(\"year\").isNotNull()) &\n",
        "    (col(\"year\") >= 2014) & (col(\"year\") <= 2019)\n",
        ")\n",
        "\n",
        "df_filtered_years.select(\"year\").distinct().orderBy(\"year\").show()\n",
        "df_filtered_years.groupBy(\"year\").count().orderBy(\"year\").show()\n",
        "\n",
        "print(\"Row count after year filtering:\", df_filtered_years.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "outputs": [],
      "metadata": {},
      "source": [
        "valid_sentiments = [\"Positive\", \"Negative\", \"Neutral\"]\n",
        "\n",
        "df_final_cleaned = df_filtered_years.filter(col(\"sentiment\").isin(valid_sentiments))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_final_cleaned = df_final_cleaned.filter(col(\"sentiment\").isin([\"Positive\", \"Negative\"]))\n",
        "df_final_cleaned.groupBy(\"year\", \"sentiment\").count().orderBy(\"year\", \"sentiment\").show()\n",
        "df_final_cleaned.groupBy(\"sentiment\").count().orderBy(\"sentiment\").show()\n",
        "print(\"Row count after removing 'Neutral':\", df_final_cleaned.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_final_cleaned.coalesce(1).write.mode(\"overwrite\").parquet(\n",
        "    \"wasbs://bronze@ds562team9datalake.blob.core.windows.net/Crypto_tweets/cleaned_tweet_data/\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_check = spark.read.parquet(\"wasbs://bronze@ds562team9datalake.blob.core.windows.net/Crypto_tweets/cleaned_tweet_data/\")\n",
        "df_check.count()\n",
        ""
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "language_info": {
      "name": "python"
    }
  }
}