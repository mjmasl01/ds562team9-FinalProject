{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 74,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Set up the configuration for accessing the storage account\n",
        "storage_account_name = \"ds562team9datalake\"\n",
        "storage_account_key = \"KXg2Djg7uRevBSpPNIVnKw/N6HpqBh+kJwDX07wkywbpU2joMZdTIBOXk30EoMMxH2d8wwb+9j0g+AStO60IWw==\"\n",
        "container = \"silver\"\n",
        "\n",
        "# Set Spark config to access the storage account\n",
        "spark.conf.set(\n",
        "    f\"fs.azure.account.key.{storage_account_name}.dfs.core.windows.net\",\n",
        "    storage_account_key\n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "outputs": [],
      "metadata": {},
      "source": [
        "tweets_df = spark.read.parquet(\"abfss://silver@ds562team9datalake.dfs.core.windows.net/historical_crypto_tweet_data/english_crypto_tweets_2014_2019.parquet\")\n",
        "news_df = spark.read.parquet(\"abfss://silver@ds562team9datalake.dfs.core.windows.net/historical_crypto_news_data/crypto_news_filtered_2013_2018.parquet\")\n",
        "prices_df = spark.read.parquet(\"abfss://silver@ds562team9datalake.dfs.core.windows.net/historical_crypto_prices/crypto_prices_2014_2021.parquet\")\n",
        "sentiment_df = spark.read.csv(\n",
        "    \"abfss://silver@ds562team9datalake.dfs.core.windows.net/historical_sentiment/Spearman_Pearson_correlation.csv\",\n",
        "    header=True,\n",
        "    inferSchema=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import to_date, col, lit, concat_ws\n",
        "from pyspark.sql.types import DateType\n",
        "\n",
        "# Ensure 'date' columns are casted to proper DateType where available\n",
        "tweets_df = tweets_df.withColumn(\"date\", to_date(col(\"date\").cast(DateType())))\n",
        "prices_df = prices_df.withColumn(\"date\", to_date(col(\"date\").cast(DateType())))\n",
        "sentiment_df = sentiment_df.withColumn(\"date\", to_date(col(\"date\").cast(DateType())))\n",
        "\n",
        "# For news_df, construct a dummy date from year since only 'year' is available\n",
        "news_df = news_df.withColumn(\n",
        "    \"date\",\n",
        "    to_date(concat_ws(\"-\", col(\"year\").cast(\"string\"), lit(\"01\"), lit(\"01\")))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "outputs": [],
      "metadata": {},
      "source": [
        "print(\"✅ tweets_df schema:\")\n",
        "tweets_df.printSchema()\n",
        "\n",
        "print(\"✅ news_df schema:\")\n",
        "news_df.printSchema()\n",
        "\n",
        "print(\"✅ prices_df schema:\")\n",
        "prices_df.printSchema()\n",
        "\n",
        "print(\"✅ sentiment_df schema:\")\n",
        "sentiment_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "news_df = news_df.withColumn(\"year\", col(\"year\").cast(IntegerType()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "sentiment_df = sentiment_df.select(\n",
        "    \"date\",\n",
        "    col(\"Close\").cast(DoubleType()),\n",
        "    col(\"tweet_sentiment\").cast(DoubleType()),\n",
        "    col(\"news_sentiment\").cast(DoubleType()),\n",
        "    col(\"Close_lag1\").cast(DoubleType()),\n",
        "    col(\"return_1d\").cast(DoubleType()),\n",
        "    col(\"tweet_sent_roll3\").cast(DoubleType()),\n",
        "    col(\"news_sent_roll3\").cast(DoubleType()),\n",
        "    col(\"volatility_3d\").cast(DoubleType()),\n",
        "    col(\"tweet_sent_roll7\").cast(DoubleType()),\n",
        "    col(\"news_sent_roll7\").cast(DoubleType()),\n",
        "    col(\"volatility_7d\").cast(DoubleType()),\n",
        "    col(\"sma_5\").cast(DoubleType()),\n",
        "    col(\"sma_10\").cast(DoubleType()),\n",
        "    col(\"rsi_14\").cast(DoubleType())\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# table aggregation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import count\n",
        "\n",
        "agg_crypto_tweets = tweets_df.groupBy(\"date\").agg(\n",
        "    count(\"*\").alias(\"tweet_count\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "outputs": [],
      "metadata": {},
      "source": [
        "agg_news_by_source = news_df.groupBy(\"date\", \"source\").agg(\n",
        "    count(\"*\").alias(\"news_count\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import avg\n",
        "\n",
        "agg_crypto_prices = prices_df.groupBy(\"date\").agg(\n",
        "    avg(\"Open\").alias(\"avg_open\"),\n",
        "    avg(\"Close\").alias(\"avg_close\"),\n",
        "    avg(\"High\").alias(\"avg_high\"),\n",
        "    avg(\"Low\").alias(\"avg_low\"),\n",
        "    avg(\"Volume\").alias(\"avg_volume\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import avg\n",
        "\n",
        "agg_sentiment_over_time = sentiment_df.groupBy(\"date\").agg(\n",
        "    avg(\"tweet_sentiment\").alias(\"avg_tweet_sentiment\"),\n",
        "    avg(\"news_sentiment\").alias(\"avg_news_sentiment\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "outputs": [],
      "metadata": {},
      "source": [
        "agg_rolling_sentiment_volatility = sentiment_df.groupBy(\"date\").agg(\n",
        "    avg(\"tweet_sent_roll3\").alias(\"avg_tweet_sent_roll3\"),\n",
        "    avg(\"news_sent_roll3\").alias(\"avg_news_sent_roll3\"),\n",
        "    avg(\"volatility_3d\").alias(\"avg_volatility_3d\"),\n",
        "    avg(\"tweet_sent_roll7\").alias(\"avg_tweet_sent_roll7\"),\n",
        "    avg(\"news_sent_roll7\").alias(\"avg_news_sent_roll7\"),\n",
        "    avg(\"volatility_7d\").alias(\"avg_volatility_7d\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "outputs": [],
      "metadata": {},
      "source": [
        "agg_rsi_vs_price = sentiment_df.select(\"date\", \"rsi_14\", \"Close\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "outputs": [],
      "metadata": {},
      "source": [
        "agg_summary_metrics = sentiment_df.groupBy(\"date\").agg(\n",
        "    avg(\"Close\").alias(\"avg_close\"),\n",
        "    avg(\"return_1d\").alias(\"avg_return_1d\"),\n",
        "    avg(\"tweet_sentiment\").alias(\"avg_tweet_sentiment\"),\n",
        "    avg(\"news_sentiment\").alias(\"avg_news_sentiment\"),\n",
        "    avg(\"volatility_3d\").alias(\"volatility_3d\"),\n",
        "    avg(\"rsi_14\").alias(\"avg_rsi_14\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# save & load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Set Gold layer base path\n",
        "gold_path = \"abfss://gold@ds562team9datalake.dfs.core.windows.net\"\n",
        "\n",
        "# Save aggregated tables\n",
        "agg_crypto_tweets.coalesce(1).write.mode(\"overwrite\").parquet(f\"{gold_path}/agg_crypto_tweets\")\n",
        "agg_news_by_source.coalesce(1).write.mode(\"overwrite\").parquet(f\"{gold_path}/agg_crypto_news_by_source\")\n",
        "agg_crypto_prices.coalesce(1).write.mode(\"overwrite\").parquet(f\"{gold_path}/agg_crypto_prices\")\n",
        "agg_sentiment_over_time.coalesce(1).write.mode(\"overwrite\").parquet(f\"{gold_path}/agg_sentiment_over_time\")\n",
        "agg_rolling_sentiment_volatility.coalesce(1).write.mode(\"overwrite\").parquet(f\"{gold_path}/agg_rolling_sentiment_volatility\")\n",
        "agg_rsi_vs_price.coalesce(1).write.mode(\"overwrite\").parquet(f\"{gold_path}/agg_rsi_vs_price\")\n",
        "agg_summary_metrics.coalesce(1).write.mode(\"overwrite\").parquet(f\"{gold_path}/agg_summary_metrics\")\n",
        "tweets_df.coalesce(1).write.mode(\"overwrite\").parquet(f\"{gold_path}/processed_crypto_tweets\")\n",
        "news_df.coalesce(1).write.mode(\"overwrite\").parquet(f\"{gold_path}/processed_crypto_news\")\n",
        "prices_df.coalesce(1).write.mode(\"overwrite\").parquet(f\"{gold_path}/processed_crypto_prices\")\n",
        "sentiment_df.coalesce(1).write.mode(\"overwrite\").parquet(f\"{gold_path}/processed_sentiment\")"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "language_info": {
      "name": "python"
    }
  }
}