{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import fastparquet\n",
        "import pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_tweet = pd.read_parquet(\"english_crypto_tweets_2014_2019.parquet\")\n",
        "df_news = pd.read_parquet(\"crypto_news_2013_2018_n_2021_2023.parquet\")\n",
        "df_price = pd.read_parquet(\"crypto_prices_2014_2021.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_tweet.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_news.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_price.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {},
      "source": [
        "from datetime import timedelta\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "from scipy.stats import spearmanr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {},
      "source": [
        "# 2) Sentiment scoring\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def score_series(df, text_col, out_col):\n",
        "    df[out_col] = df[text_col].apply(lambda t: analyzer.polarity_scores(t)[\"compound\"])\n",
        "    return df\n",
        "\n",
        "df_tweet = score_series(df_tweet, \"text\", \"tweet_sentiment\")\n",
        "df_news  = score_series(df_news,  \"text\", \"news_sentiment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {},
      "source": [
        "# 1) First try to parse full YYYY-MM-DD (and time if present)\n",
        "parsed = pd.to_datetime(df_tweet[\"date\"], errors=\"coerce\", infer_datetime_format=True)\n",
        "\n",
        "# 2) Find the ones that failed (NaT) but are exactly 4 digits â†’ treat as year\n",
        "mask_year_only = parsed.isna() & df_tweet[\"date\"].str.fullmatch(r\"\\d{4}\")\n",
        "\n",
        "# Build a YYYY-01-01 string for those\n",
        "year_as_date_str = df_tweet.loc[mask_year_only, \"date\"] + \"-01-01\"\n",
        "parsed.loc[mask_year_only] = pd.to_datetime(year_as_date_str, format=\"%Y-%m-%d\")\n",
        "\n",
        "# 3) Assign back as Python dates\n",
        "df_tweet[\"date\"] = parsed.dt.date\n",
        "\n",
        "# 4) (Optional) Drop any rows that still failed to parse\n",
        "df_tweet = df_tweet[df_tweet[\"date\"].notna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_tweet.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_price[\"date\"]  = pd.to_datetime(df_price[\"Date\"]).dt.date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {},
      "source": [
        "# 3) Normalize & aggregate by date\n",
        "df_news[\"date\"] = pd.to_datetime(df_news[\"year\"], format=\"%Y\").dt.date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "metadata": {},
      "source": [
        "# daily mean sentiment\n",
        "tweet_agg = (\n",
        "    df_tweet.groupby(\"date\")[\"tweet_sentiment\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"sentiment_score\": \"tweet_sentiment\"})\n",
        ")\n",
        "\n",
        "news_agg = (\n",
        "    df_news.groupby(\"date\")[\"news_sentiment\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"sentiment_score\": \"news_sentiment\"})\n",
        ")\n",
        "\n",
        "# 4) Merge with price\n",
        "df = (\n",
        "    df_price[[\"date\", \"Close\"]]\n",
        "    .merge(tweet_agg, on=\"date\", how=\"left\")\n",
        "    .merge(news_agg, on=\"date\", how=\"left\")\n",
        "    .fillna(0)   # fill missing sentiment days with 0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "metadata": {},
      "source": [
        "df[\"Close_lag1\"]   = df[\"Close\"].shift(1)\n",
        "df[\"return_1d\"]    = (df[\"Close\"] - df[\"Close_lag1\"]) / df[\"Close_lag1\"]\n",
        "\n",
        "# 4.2 rolling windows\n",
        "for w in (3,7):\n",
        "    df[f\"tweet_sent_roll{w}\"] = df[\"tweet_sentiment\"].rolling(w).mean()\n",
        "    df[f\"news_sent_roll{w}\"]  = df[\"news_sentiment\"].rolling(w).mean()\n",
        "    df[f\"volatility_{w}d\"]    = df[\"return_1d\"].rolling(w).std()\n",
        "\n",
        "# 4.3 simple moving average (SMA)\n",
        "for w in (5,10):\n",
        "    df[f\"sma_{w}\"] = df[\"Close\"].rolling(w).mean()\n",
        "\n",
        "# 4.4 RSI (14-day)\n",
        "delta = df[\"Close\"].diff()\n",
        "gain  = delta.clip(lower=0)\n",
        "loss  = -delta.clip(upper=0)\n",
        "avg_gain = gain.rolling(14).mean()\n",
        "avg_loss = loss.rolling(14).mean()\n",
        "rs = avg_gain / avg_loss\n",
        "df[\"rsi_14\"] = 100 - (100 / (1 + rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "metadata": {},
      "source": [
        "corr_df = df.dropna(subset=[\n",
        "    \"tweet_sentiment\",\"news_sentiment\",\"tweet_sent_roll3\",\"sma_5\",\"rsi_14\"\n",
        "])\n",
        "\n",
        "print(\"Pearson corr tweet vs Close:\", \n",
        "      corr_df[\"tweet_sentiment\"].corr(corr_df[\"Close\"]))\n",
        "print(\"Spearman corr  tweet vs Close:\", \n",
        "      spearmanr(corr_df[\"tweet_sentiment\"], corr_df[\"Close\"])[0])\n",
        "\n",
        "print(\"Pearson corr news vs Close:\", \n",
        "      corr_df[\"news_sentiment\"].corr(corr_df[\"Close\"]))\n",
        "print(\"Spearman corr  news vs Close:\", \n",
        "      spearmanr(corr_df[\"news_sentiment\"], corr_df[\"Close\"])[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "metadata": {},
      "source": [
        "df[\"next_close\"] = df[\"Close\"].shift(-1)\n",
        "df[\"label\"]      = (df[\"next_close\"] > df[\"Close\"]).astype(int)\n",
        "model_df = df.dropna(subset=[\"label\"])\n",
        "\n",
        "feature_cols = [\"tweet_sentiment\",\"news_sentiment\",\"tweet_sent_roll3\",\"tweet_sent_roll7\",\"news_sent_roll3\",\"news_sent_roll7\",\"sma_5\",\"sma_10\",\"rsi_14\",\"volatility_3d\"]\n",
        "X = model_df[feature_cols]\n",
        "y = model_df[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [],
      "metadata": {},
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "probs = rf.predict_proba(X_test)[:,1]\n",
        "fpr, tpr, th = roc_curve(y_test, probs)\n",
        "opt_thresh = th[np.argmax(tpr - fpr)]\n",
        "y_pred = (probs >= opt_thresh).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "outputs": [],
      "metadata": {},
      "source": [
        "print(\"RandomForestClassifier\")\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Test ROC AUC:\", roc_auc_score(y_test, rf.predict_proba(X_test)[:,1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [],
      "metadata": {},
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xclf = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    scale_pos_weight=(len(y_train[y_train==0])/len(y_train[y_train==1])),\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric=\"auc\"\n",
        ")\n",
        "xclf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "outputs": [],
      "metadata": {},
      "source": [
        "y_pred_xgb = xclf.predict(X_test)\n",
        "print(\"XGBoost\")\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "print(\"Test ROC AUC:\", roc_auc_score(y_test, rf.predict_proba(X_test)[:,1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "outputs": [],
      "metadata": {},
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "scores = cross_val_score(rf, X, y, cv=tscv, scoring=\"roc_auc\")\n",
        "print(\"CV AUC scores:\", scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "outputs": [],
      "metadata": {},
      "source": [
        "from xgboost import XGBClassifier\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "xgb = XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2) Specify the hyperparameter search space\n",
        "search_spaces = {\n",
        "    'max_depth': Integer(3, 10),\n",
        "    'learning_rate': Real(1e-3, 1e-1, prior='log-uniform'),\n",
        "    'subsample': Real(0.5, 1.0),\n",
        "    'colsample_bytree': Real(0.5, 1.0),\n",
        "    'reg_alpha': Real(1e-5, 1e2, prior='log-uniform'),\n",
        "    'reg_lambda': Real(1e-5, 1e2, prior='log-uniform'),\n",
        "    'min_child_weight': Integer(1, 10),\n",
        "    'n_estimators': Integer(50, 300)\n",
        "}\n",
        "\n",
        "# 3) Use TimeSeriesSplit for cross-validation\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# 4) Set up Bayesian search with BayesSearchCV\n",
        "bayes_cv = BayesSearchCV(\n",
        "    estimator=xgb,\n",
        "    search_spaces=search_spaces,\n",
        "    n_iter=32,                    # number of parameter settings sampled\n",
        "    scoring='roc_auc',\n",
        "    cv=tscv,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "outputs": [],
      "metadata": {},
      "source": [
        "# 5) Run the search\n",
        "bayes_cv.fit(X_train, y_train)\n",
        "\n",
        "# 6) Output best parameters and score\n",
        "print(\"Best AUC (CV):\", bayes_cv.best_score_)\n",
        "print(\"Best hyperparameters:\", bayes_cv.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "outputs": [],
      "metadata": {},
      "source": [
        "# 7) Evaluate on test set\n",
        "best_model = bayes_cv.best_estimator_\n",
        "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
        "y_pred_bayes_xgb = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "print(\"Test ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
        "print(classification_report(y_test, y_pred_bayes_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "outputs": [],
      "metadata": {},
      "source": [
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "\n",
        "# Prepare\n",
        "df[\"ret_1d\"] = df[\"Close\"].pct_change(1)\n",
        "df[\"ret_next\"] = df[\"ret_1d\"].shift(-1)\n",
        "reg_df = df.dropna(subset=[\"ret_next\"])\n",
        "\n",
        "Xr = reg_df[feature_cols]\n",
        "yr = reg_df[\"ret_next\"]\n",
        "Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr, yr, test_size=0.2, shuffle=False)\n",
        "\n",
        "# 1) Define & train\n",
        "hgb = HistGradientBoostingRegressor(\n",
        "    max_iter=100,\n",
        "    random_state=42\n",
        ")\n",
        "hgb.fit(Xr_train, yr_train)\n",
        "\n",
        "# 2) Evaluate\n",
        "yr_pred = hgb.predict(Xr_test)\n",
        "print(\"RMSE:\", root_mean_squared_error(yr_test, yr_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "outputs": [],
      "metadata": {},
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
        "search_spaces2 = {\n",
        "    \"learning_rate\":    Real(1e-3, 1e-1, prior=\"log-uniform\"),\n",
        "    \"max_iter\":         Integer(50, 500),\n",
        "    \"max_depth\":        Integer(2, 20),\n",
        "    \"min_samples_leaf\": Integer(1, 50),\n",
        "    \"l2_regularization\":Real(1e-5, 1e1, prior=\"log-uniform\"),\n",
        "}\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "bayes_hgb = BayesSearchCV(\n",
        "    estimator=HistGradientBoostingRegressor(random_state=42),\n",
        "    search_spaces=search_spaces2,\n",
        "    scoring=\"neg_root_mean_squared_error\",\n",
        "    cv=tscv,\n",
        "    n_iter=32,     \n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 5) Run the search\n",
        "bayes_hgb.fit(Xr_train, yr_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "outputs": [],
      "metadata": {},
      "source": [
        "print(\"Best params:\", bayes_hgb.best_params_)\n",
        "print(\"Best CV RMSE:\", -bayes_hgb.best_score_)\n",
        "\n",
        "# 6) Evaluate on hold-out test set\n",
        "best_hgb = bayes_hgb.best_estimator_\n",
        "yr_pred2 = best_hgb.predict(Xr_test)\n",
        "rmse_test = root_mean_squared_error(yr_test, yr_pred2)\n",
        "print(\"Test RMSE:\", rmse_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "outputs": [],
      "metadata": {},
      "source": [
        "import joblib\n",
        "joblib.dump(best_hgb, \"best_hgb_model.pkl\")"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "language_info": {
      "name": "python"
    }
  }
}