{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "run_control": {
          "frozen": false
        },
        "editable": true
      },
      "source": [
        "import joblib\n",
        "from io import BytesIO\n",
        "from azure.storage.filedatalake import DataLakeServiceClient\n",
        "import pandas as pd\n",
        "import requests\n",
        "import tweepy\n",
        "import urllib.parse\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {},
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 3) RECENT TWEETS VIA TWEEPY (last 30 days)\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "encoded_token = \"AAAAAAAAAAAAAAAAAAAAAAAs1AEAAAAAwSqw%2FQMhvxHeHOKIT2H5ro%2Ffcfw%3DdBWrxm1gxUhHRX8maJfxo1uBB4vAele6eqLKexEdz99ntbM8YQ\"\n",
        "TWITTER_BEARER_TOKEN = urllib.parse.unquote(encoded_token)\n",
        "if not TWITTER_BEARER_TOKEN:\n",
        "    raise ValueError(\"Set TWITTER_BEARER_TOKEN env var first\")\n",
        "\n",
        "client = tweepy.Client(bearer_token=TWITTER_BEARER_TOKEN, wait_on_rate_limit=True)\n",
        "query = \"(bitcoin OR btc OR #bitcoin OR #btc) lang:en -is:retweet\"\n",
        "\n",
        "# Tweepy recent search only returns up to 7 days on standard API.\n",
        "# If you have Academic access, use `search_all_tweets` instead.\n",
        "start_time = thirty_ago.isoformat(timespec=\"seconds\") + \"Z\"\n",
        "\n",
        "paginator = tweepy.Paginator(\n",
        "    client.search_recent_tweets,\n",
        "    query,\n",
        "    tweet_fields=[\"created_at\",\"text\"],\n",
        "    start_time=start_time,\n",
        "    max_results=100\n",
        ")\n",
        "\n",
        "tweets = []\n",
        "for page in paginator:\n",
        "    if page.data:\n",
        "        tweets.extend(page.data)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "df_tweet = pd.DataFrame([\n",
        "    {\n",
        "      \"date\": t.created_at.date(),\n",
        "      \"text\": t.text\n",
        "    }\n",
        "    for t in tweets\n",
        "])\n",
        "df_tweet[\"year\"] = pd.to_datetime(df_tweet[\"date\"]).dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 2) Aggregate tweet by day\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "tweet_agg = (\n",
        "    df_tweet\n",
        "      .groupby(\"date\")\n",
        "      .agg(tweet_sentiment=(\"sentiment_score\", \"mean\"),\n",
        "           tweet_count    =(\"sentiment_score\", \"size\"))\n",
        "      .reset_index()\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "language_info": {
      "name": "python"
    }
  }
}